{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cbcab-2cad-40e5-a5a6-11094c60c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Standard Library ───────────────────────────────────────────────────────────\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from itertools import cycle\n",
    "\n",
    "# ── Data Handling & Numerics ───────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "\n",
    "# ── PyTorch Ecosystem ──────────────────────────────────────────────────────────\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ── Computer Vision & Augmentations ────────────────────────────────────────────\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pydicom import dcmread\n",
    "\n",
    "# ── Scikit-Learn & Statistics ─────────────────────────────────────────────────\n",
    "import sklearn\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, auc, roc_curve, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from scipy import interp\n",
    "from scipy.stats import ttest_rel, ttest_ind\n",
    "\n",
    "# ── Visualization ─────────────────────────────────────────────────────────────\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ── Grad-CAM & Explainability ─────────────────────────────────────────────────\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "    AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    ")\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.feature_factorization.deep_feature_factorization import (\n",
    "    DeepFeatureFactorization\n",
    ")\n",
    "import pytorch_grad_cam.utils.reshape_transforms\n",
    "import pytorch_grad_cam.metrics.cam_mult_image\n",
    "import pytorch_grad_cam.metrics.road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17d240-a9e5-48db-a7e5-5f040625e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Dataset Directory\")\n",
    "visualization_dir = \"visualization_dir\"\n",
    "model_save_dir = \"Directory_Model\"\n",
    "df = pd.read_csv(\"PLOSONE_DF-Time.csv\") \n",
    "df[\"image_id\"] = np.arange(len(df))\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8343411",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [ 'class_0','class_1']\n",
    "class_labels = { name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 6\n",
    "num_classes = class_labels \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f63273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "class OctModel3D(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = r3d_18(pretrained=True)\n",
    "        self.model.stem[0] = nn.Conv3d(\n",
    "            in_channels=1,\n",
    "            out_channels=self.model.stem[0].out_channels,\n",
    "            kernel_size=self.model.stem[0].kernel_size,\n",
    "            stride=self.model.stem[0].stride,\n",
    "            padding=self.model.stem[0].padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expects shape: (Batch, 1, Depth, Height, Width)\n",
    "        return self.model(x)\n",
    "        \n",
    "model = OctModel3D(num_classes=2)\n",
    "model = model.to(device)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848209a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_volume(dicom_dir, target_shape=(64, 256, 256), cache_dir=None, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Load a series of DICOM files into a resized 3D tensor with GPU-based resizing.\n",
    "    \"\"\"\n",
    "    slices = []\n",
    "\n",
    "    if os.path.isfile(dicom_dir):\n",
    "        ds = pydicom.dcmread(dicom_dir)\n",
    "        slices.append(ds.pixel_array)\n",
    "    else:\n",
    "        for filename in sorted(os.listdir(dicom_dir)):\n",
    "            if filename.endswith('.dcm'):\n",
    "                dicom_path = os.path.join(dicom_dir, filename)\n",
    "                ds = pydicom.dcmread(dicom_path)\n",
    "                slices.append(ds.pixel_array)\n",
    "\n",
    "    if not slices:\n",
    "        raise ValueError(f\"No valid DICOM slices found in: {dicom_dir}\")\n",
    "\n",
    "    # Stack slices => shape [Depth, Height, Width]\n",
    "    volume = np.stack(slices, axis=0).astype(np.float32)\n",
    "\n",
    "    # Normalize the volume to [0, 1]\n",
    "    volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume) + 1e-8)\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    volume = torch.tensor(volume)\n",
    "\n",
    "    # Add batch=1, channel=1 => shape [1, 1, D, H, W]\n",
    "    if volume.ndim == 3:\n",
    "        volume = volume.unsqueeze(0).unsqueeze(0)\n",
    "    elif volume.ndim == 4:\n",
    "        volume = volume.unsqueeze(0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected volume shape {volume.shape}\")\n",
    "\n",
    "    # Resize to target_shape => [1,1,*target_shape]\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        volume = volume.cuda()\n",
    "        volume = F.interpolate(volume, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "        volume = volume.cpu()\n",
    "    else:\n",
    "        volume = F.interpolate(volume, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "\n",
    "    # Remove batch dimension => shape [1, D,H,W]\n",
    "    volume = volume.squeeze(0)\n",
    "\n",
    "    # Validate final shape\n",
    "    if volume.shape != (1, *target_shape):\n",
    "        raise ValueError(f\"Unexpected shape after resizing: {volume.shape}, expected: (1, {target_shape})\")\n",
    "\n",
    "    return volume\n",
    "\n",
    "class OctDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, class_names, target_shape=(64, 256, 256), cache_dir=None, use_gpu=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.class_names = class_names\n",
    "        self.target_shape = target_shape\n",
    "        self.cache_dir = cache_dir\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dicom_dir = self.df.iloc[idx]['path3D']\n",
    "        try:\n",
    "            volume = load_dicom_volume(dicom_dir, target_shape=self.target_shape, cache_dir=self.cache_dir, use_gpu=self.use_gpu)\n",
    "        except ValueError as e:\n",
    "            raise RuntimeError(f\"Error loading DICOM at index {idx}: {e}\")\n",
    "\n",
    "        # volume => shape [1, D,H,W]\n",
    "        if volume.ndim != 4:\n",
    "            raise ValueError(f\"Volume shape is {volume.shape}, expected 4D (1, D, H, W)\")\n",
    "\n",
    "        # Load labels\n",
    "        labels = self.df.iloc[idx][self.class_names].values.astype(np.float32)\n",
    "        labels = torch.from_numpy(labels)\n",
    "\n",
    "        # Get sample ID\n",
    "        sample_id = self.df.iloc[idx]['image_id']\n",
    "        return volume, labels, sample_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64890b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e354cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def train_one_fold(v, t, model, criterion, optimizer,\n",
    "                   dataloader_train, dataloader_valid,\n",
    "                   model_save_dir, patience=10):\n",
    "    \n",
    "    val_fold_results = []\n",
    "    best_fold_avg_precision = 0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_path = None\n",
    "    epoch_times = []\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        print(f\"[{get_current_time()}] Epoch {epoch + 1}/{N_EPOCHS}\")\n",
    "\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        tr_loss = 0\n",
    "        for _, batch in enumerate(dataloader_train):\n",
    "            images, labels = batch[0].to(device).float(), batch[1].to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # forward => shape [batch_size, 2]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _, batch in enumerate(dataloader_valid):\n",
    "                images, labels = batch[0].to(device).float(), batch[1].to(device).float()\n",
    "                outputs = model(images)  # shape [batch_size, 2]\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.extend(outputs.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        val_preds_np = np.array(val_preds)   # shape [N, 2]\n",
    "        val_labels_np = np.array(val_labels) # shape [N, 2]\n",
    "\n",
    "        try:\n",
    "            avg_precision_current = average_precision_score(val_labels_np[:, 1], val_preds_np[:, 1])\n",
    "        except ValueError:\n",
    "            avg_precision_current = 0.0\n",
    "\n",
    "        print(f\"[{get_current_time()}] Average Precision Current Validation: {avg_precision_current:.4f}\")\n",
    "\n",
    "        # ---- Model Saving ----\n",
    "        if avg_precision_current > best_fold_avg_precision:\n",
    "            best_fold_avg_precision = avg_precision_current\n",
    "            epochs_no_improve = 0\n",
    "            best_model_path = os.path.join(\n",
    "                model_save_dir, f\"Model{v}_T{t}Time.pth\"\n",
    "            )\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"[{get_current_time()}] Best Model Saved at: {best_model_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"[{get_current_time()}] Early stopping at epoch: {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        print(f\"[{get_current_time()}] Time for E {epoch + 1}: {epoch_time:.2f} s\")\n",
    "\n",
    "        # Record stats\n",
    "        val_fold_results.append({\n",
    "            'TEST': t,\n",
    "            'VAL': v,\n",
    "            'epoch': epoch,\n",
    "            'train_loss': tr_loss / len(dataloader_train),\n",
    "            'valid_loss': val_loss / len(dataloader_valid),\n",
    "            'valid_avg_precision': avg_precision_current,\n",
    "            'time': epoch_time\n",
    "        })\n",
    "\n",
    "    #Plot epoch times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(epoch_times)+1), epoch_times, marker='o')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.title(f\"Epoch Timing - Fold {v}-{t}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return val_fold_results, best_fold_avg_precision, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated results list\n",
    "aggregated_results = []\n",
    "\n",
    "# Loop through test and validation folds\n",
    "for test_fold in range(5):\n",
    "    for val_fold in range(5):\n",
    "        if test_fold != val_fold:\n",
    "            # Arrays to store test results\n",
    "            aggregated_test_targets = []\n",
    "            aggregated_test_probabilities = []\n",
    "            aggregated_test_ids = []\n",
    "\n",
    "            # 1) Initialize the model and reset weights\n",
    "            model = OctModel3D(num_classes=2).to(device)\n",
    "            model.apply(reset_weights)\n",
    "\n",
    "            # 2) Prepare dataset splits\n",
    "            val_df = df[df['fold'] == val_fold].reset_index(drop=True)\n",
    "            train_df = df[\n",
    "                (df['fold'] != test_fold) & (df['fold'] != val_fold)\n",
    "            ].reset_index(drop=True)\n",
    "            test_df = df[df['fold'] == test_fold].reset_index(drop=True)\n",
    "\n",
    "            print(\"!!!!!\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "            # 3) Prepare dataloaders\n",
    "            dataset_train = OctDataset(df=train_df, class_names=class_names)\n",
    "            dataset_valid = OctDataset(df=val_df, class_names=class_names)\n",
    "            dataset_test = OctDataset(df=test_df, class_names=class_names)\n",
    "\n",
    "            num_workers = min(os.cpu_count(), 8)\n",
    "            dataloader_train = DataLoader(\n",
    "                dataset_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=0,\n",
    "                pin_memory=True\n",
    "            )\n",
    "            dataloader_valid = DataLoader(\n",
    "                dataset_valid,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                pin_memory=True\n",
    "            )\n",
    "            dataloader_test = DataLoader(\n",
    "                dataset_test,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=0\n",
    "            )\n",
    "\n",
    "            # 4) Training setup\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "            # 5) Train & validate (train_one_fold is adapted for 2 classes)\n",
    "            best_model_path_local = os.path.join(\n",
    "                model_save_dir, f\"Model-T{test_fold}_V{val_fold}-Time.pth\"\n",
    "            )\n",
    "            val_fold_results, best_fold_roc_auc, best_model_path = train_one_fold(\n",
    "                test_fold,\n",
    "                val_fold,\n",
    "                model,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                dataloader_train,\n",
    "                dataloader_valid,\n",
    "                model_save_dir,\n",
    "                patience=10\n",
    "            )\n",
    "\n",
    "            # 6) Load the best model for testing\n",
    "            model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "            model.eval()\n",
    "\n",
    "            # 7) Test phase (collect predictions for ALL test samples)\n",
    "            fold_test_targets = []\n",
    "            fold_test_probabilities = []\n",
    "            fold_test_ids = []\n",
    "            predictions = []\n",
    "\n",
    "            for batch in dataloader_test:\n",
    "                images, labels, ids = batch[0].to(device).float(), batch[1].to(device).float(), batch[2]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # model outputs shape [batch_size, 2]\n",
    "                    outputs = model(images)\n",
    "                    # probabilities shape [batch_size, 2]\n",
    "                    probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "                # Predicted class = argmax => 0 or 1\n",
    "                batch_predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "                # Extend predictions/results\n",
    "                predictions.extend(batch_predictions)\n",
    "                fold_test_targets.extend(labels.cpu().numpy())       \n",
    "                fold_test_probabilities.extend(probabilities.tolist())\n",
    "                fold_test_ids.extend(ids.numpy())\n",
    "\n",
    "            # Convert to numpy arrays\n",
    "            test_targets_np = np.stack(fold_test_targets)\n",
    "            test_probabilities_np = np.stack(fold_test_probabilities)\n",
    "\n",
    "            # 7a) Compute ROC AUC for 2 classes:\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(\n",
    "                    test_targets_np[:, 1],  # ground-truth for positive class\n",
    "                    test_probabilities_np[:, 1]  # predicted probability for positive class\n",
    "                )\n",
    "            except ValueError:\n",
    "                roc_auc = 0.0\n",
    "\n",
    "            print(f\"ROC AUC Score [Test Fold={test_fold}, Val Fold={val_fold}]: {roc_auc:.4f}\")\n",
    "\n",
    "            # 8) Identify correct predictions\n",
    "            actual_classes = np.argmax(test_targets_np, axis=1)  # shape (N,)\n",
    "            correct_indices = [\n",
    "                i for i in range(len(predictions))\n",
    "                if predictions[i] == actual_classes[i]\n",
    "            ]\n",
    "            print(f\"Found {len(correct_indices)} correctly predicted samples.\")\n",
    "\n",
    "            # 12) Store final results for this fold combination \n",
    "            sub = pd.DataFrame(\n",
    "                fold_test_probabilities, \n",
    "                columns=[\"pred0\", \"pred1\"]\n",
    "            )\n",
    "            sub[\"image_id\"] = fold_test_ids\n",
    "            sub[\"test_fold\"] = test_fold\n",
    "            sub[\"val_fold\"] = val_fold\n",
    "            sub[\"predicted_class\"] = predictions\n",
    "            aggregated_results.append(sub)\n",
    "\n",
    "# Concatenate final results\n",
    "final_results = pd.concat(aggregated_results, ignore_index=True)\n",
    "print(\"Final Results (head):\")\n",
    "print(final_results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
