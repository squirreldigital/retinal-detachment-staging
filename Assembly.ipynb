{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b140ddad-84c2-4afd-aab9-4ff88a4cb64d",
   "metadata": {},
   "source": [
    "# Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff62313-eb0d-461c-b254-95388243afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Standard Library ───────────────────────────────────────────────────────────\n",
    "import os\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Data Handling & ML ───────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fcac2-6d42-489e-8a60-8405ab475d19",
   "metadata": {},
   "source": [
    "# Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da847b97-8996-4588-83b2-e35bae9a4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dir. Reference for Imagepath\n",
    "os.chdir(\"Dataset Directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be15ec-7c2b-4500-bc83-9b88c274333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Preassembled csv. with Combined Targets and Image Paths\n",
    "csv_file_path = 'Basic.csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9023fc-2d6f-4ae4-91d0-6930cda9d3cb",
   "metadata": {},
   "source": [
    "# Stratification of Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ffd57-1995-4ab6-95e7-d79f7c401da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign 5-fold CV labels while\n",
    "\n",
    "1. grouping first by ID_Physio for rows where Non-RRD labels == 1.0\n",
    "2. grouping the rest by PN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ──  aliases ────────────────────────────────\n",
    "LABEL_COL   = \"Oct_stage\"      \n",
    "GROUP_COL_1 = \"ID_Non_RRD\"\n",
    "GROUP_COL_2 = \"PN\"\n",
    "\n",
    "\n",
    "# Description of original labels to true stages.\n",
    "df = df.rename(columns={\n",
    "    \"OCT staging (1-5) 1:1,2:2,3:3a, 4:3b,5:4,6:5\": LABEL_COL\n",
    "})\n",
    "\n",
    "# ── initialise 'fold' ──\n",
    "df[\"fold\"] = -1\n",
    "\n",
    "# ── PASS 1 ─────────────────────────────────────────────────────────────────────\n",
    "mask_pass1 = (df[\"Non_RRD\"] == 1.0) & df[GROUP_COL_1].notna()\n",
    "filtered_df = df.loc[mask_pass1]\n",
    "\n",
    "id_summary = (\n",
    "    filtered_df\n",
    "      .groupby(GROUP_COL_1, sort=False)\n",
    "      .agg(count=(\"fold\", \"size\"), label=(LABEL_COL, \"first\"))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (_, test_idx) in enumerate(skf.split(id_summary, id_summary[\"label\"])):\n",
    "    ids_in_fold = id_summary.loc[test_idx, GROUP_COL_1]\n",
    "    df.loc[df[GROUP_COL_1].isin(ids_in_fold), \"fold\"] = fold\n",
    "\n",
    "# ── PASS 2  ─────────────────────────────────────────\n",
    "remaining_df = df.loc[df[\"fold\"] == -1]\n",
    "\n",
    "pn_summary = (\n",
    "    remaining_df\n",
    "      .groupby(GROUP_COL_2, sort=False)\n",
    "      .agg(count=(\"fold\", \"size\"), label=(LABEL_COL, \"first\"))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "for fold, (_, test_idx) in enumerate(skf.split(pn_summary, pn_summary[\"label\"])):\n",
    "    pns_in_fold = pn_summary.loc[test_idx, GROUP_COL_2]\n",
    "    df.loc[df[GROUP_COL_2].isin(pns_in_fold) & (df[\"fold\"] == -1), \"fold\"] = fold\n",
    "    \n",
    "if (df[\"fold\"] == -1).any():\n",
    "    raise RuntimeError(\n",
    "        f\"{(df['fold'] == -1).sum()} rows never received a fold assignment.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e1056f-ab27-4651-8d4b-17326fdead11",
   "metadata": {},
   "source": [
    "# Extract DICOM Shape, Filter for Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7466eabe-fdf5-4bcc-a68b-ab5d7b3a8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1. helper ──────────────────────────────────────────────────────────────────\n",
    "def get_dicom_shape(fp: Path | str) -> tuple[int, ...] | str:\n",
    "    try:\n",
    "        dcm = pydicom.dcmread(fp, force=True)          \n",
    "        return dcm.pixel_array.shape if hasattr(dcm, \"pixel_array\") else \"No Pixel Array\"\n",
    "    except Exception as exc:                           \n",
    "        return str(exc)\n",
    "\n",
    "# ── 2. announce work ───────────────────────────────────────────────────────────\n",
    "total_rows = len(df)\n",
    "print(f\"Starting scan… {total_rows} paths to inspect\")\n",
    "\n",
    "# ── 3. scan every path ─────────────────────────────────────────────────────────\n",
    "progress_step = max(1, total_rows // 100)             # print every ~1 %\n",
    "shapes: list[tuple[int, ...] | str] = []\n",
    "\n",
    "for idx, path_str in enumerate(df[\"path3D\"], start=1):\n",
    "    path = Path(path_str)\n",
    "\n",
    "    shapes.append(get_dicom_shape(path) if path.exists() else \"File Not Found\")\n",
    "\n",
    "    if idx % progress_step == 0 or idx == total_rows:\n",
    "        pct = (idx / total_rows) * 100\n",
    "        print(f\"  {pct:5.1f}%  ({idx}/{total_rows})\")\n",
    "df[\"shape\"] = shapes\n",
    "\n",
    "# ── 4. keep only the target shape ──────────────────────────────────────────────\n",
    "TARGET_SHAPE = (256, 992, 512)\n",
    "df_filtered = df[df[\"shape\"] == TARGET_SHAPE]\n",
    "\n",
    "# ── 5. stats & output ──────────────────────────────────────────────────────────\n",
    "shape_counts = Counter(df_filtered[\"shape\"])\n",
    "shape_summary = (\n",
    "    pd.DataFrame(shape_counts.items(), columns=[\"Shape\", \"Count\"])\n",
    "        .sort_values(\"Count\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFiltered unique shapes and counts\")\n",
    "print(shape_summary)\n",
    "\n",
    "csv_out = Path(\"PLOSONE_DF.csv\")\n",
    "df_filtered.to_csv(csv_out, index=False)\n",
    "df = df_filtered                                        \n",
    "print(f\"\\nFiltered dataframe saved to {csv_out}. Remaining rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d151826-08b6-49b3-a224-02abb09edde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered\n",
    "df[\"image_id\"] = np.arange(len(df)) \n",
    "df_with_folds = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14316ee-f35a-47e8-8266-f1f8bd9407a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = df.isna().any(axis=1)\n",
    "df_with_nans = df_with_folds[rows_with_nan]\n",
    "if not df_with_nans.empty:\n",
    "    print(\"Columns in the DataFrame with NaN values:\")\n",
    "    print(df_with_nans.columns.tolist())\n",
    "else:\n",
    "    print(\"No NaN values found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabe682-1228-4ee8-a576-978e7e769f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_path_with_folds = 'PLOSONE_DF.csv'\n",
    "df_with_folds = pd.read_csv(input_csv_path_with_folds)\n",
    "\n",
    "df_with_folds['Path'] = df_with_folds['Path'].str.replace(r'\\\\', '/', regex=True)\n",
    "df_with_folds['path3D'] = df_with_folds['path3D'].str.replace(r'\\\\', '/', regex=True)\n",
    "\n",
    "df_with_folds['PN'] = df_with_folds['PN'].astype(str)\n",
    "\n",
    "output_final_csv_path = 'PLOSONE_DF.csv'\n",
    "df_with_folds.to_csv(output_final_csv_path, index=False)\n",
    "print(f\"Final CSV file with required columns and normalized image paths saved to {output_final_csv_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d7a4db-8b65-4e52-af5a-dd3f25217114",
   "metadata": {},
   "source": [
    "# Label Management for MLA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f5c54-1906-467a-8cb2-ba6c32eaeb37",
   "metadata": {},
   "source": [
    "## Preparation for MLA: RRD Stages - 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03c7bb-3e18-4f35-ac9a-d5c5c7216434",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputafterfilter = 'PLOSONE_DF.csv'\n",
    "df = pd.read_csv(inputafterfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201663b-017c-4323-8824-c43b56e6f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_staging_col = 'OCT staging (1-5) 1:1,2:2,3:3a, 4:3b,5:4,6:5'\n",
    "\n",
    "df['class_0'] = 0\n",
    "df['class_1'] = 0\n",
    "df['class_2'] = 0\n",
    "df['class_3'] = 0\n",
    "df['class_4'] = 0\n",
    "df['class_5'] = 0\n",
    "\n",
    "def update_labels(row):\n",
    "    if row[oct_staging_col] == 0:\n",
    "        row['class_0'] = 1\n",
    "    elif row[oct_staging_col] == 1:\n",
    "        row['class_1'] = 1\n",
    "    elif row[oct_staging_col] == 2:\n",
    "        row['class_2'] = 1\n",
    "    elif row[oct_staging_col] == 3:\n",
    "        row['class_3'] = 1\n",
    "    elif row[oct_staging_col] == 4:\n",
    "        row['class_4'] = 1\n",
    "    elif row[oct_staging_col] == 5:\n",
    "        row['class_5'] = 1\n",
    "    elif row[oct_staging_col] == 6:\n",
    "        row['class_5'] = 1    \n",
    "    return row\n",
    "df = df.apply(update_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b0a0c-6d6c-414e-b754-bf653b862567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- settings ---------------------------------------------------------------\n",
    "oct_staging_col = 'OCT staging (1-5) 1:1,2:2,3:3a, 4:3b,5:4,6:5'\n",
    "class_cols      = [f'class_{i}' for i in range(6)]\n",
    "\n",
    "rows = []\n",
    "for i in range(6):\n",
    "    mask = df[class_cols[i]] == 1\n",
    "    row  = df.loc[mask].head(1)\n",
    "    if not row.empty:\n",
    "        rows.append(row)\n",
    "\n",
    "# --- concatenate ---------------------------------------------------\n",
    "sample_per_class = pd.concat(rows, ignore_index=True)\n",
    "print(sample_per_class)        \n",
    "sample_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48694217-53ef-4f2f-8a8c-57a29438dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5']\n",
    "sum_of_classes = df[columns_of_interest].sum()\n",
    "print(sum_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bda83e-04f9-4145-858f-e5e43f557085",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['class_1', 'class_2', 'class_3', 'class_4', 'class_5']\n",
    "instances_with_ones = (df[columns_of_interest] == 1).any(axis=1).sum()\n",
    "print(\"Number of instances with at least one '1' in class_1 to class_5:\", instances_with_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4dfe9c-cd59-45b3-aa0a-e2e1a9ff0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('PLOSONE_DF-Stages', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692aa7c3-b41a-40b3-9581-b8575fe363ab",
   "metadata": {},
   "source": [
    "# Preparation for MLA: Macular off vs. Macular on vs. Non-RRD - 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc83d7f-2b1f-437a-a67c-0d007f3bdba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputafterfilter = 'PLOSONE_DF.csv'\n",
    "df = pd.read_csv(inputafterfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9defa-278f-4f08-8d4c-c89bc1d822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Macular status? On:1, Off:2'] = pd.to_numeric(df['Macular status? On:1, Off:2'], errors='coerce') \\\n",
    "                        .fillna(0) \\\n",
    "                        .astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2db015-3941-4b2f-893e-536e209f9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_0'] = 0\n",
    "df['class_1'] = 0\n",
    "df['class_2'] = 0\n",
    "df.loc[df[\"Macular status? On:1, Off:2\"] == 0, 'class_0'] = 1\n",
    "df.loc[df[\"Macular status? On:1, Off:2\"] == 1, 'class_1'] = 1\n",
    "df.loc[df[\"Macular status? On:1, Off:2\"] == 2, 'class_2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d010b13-6198-40cd-9d5b-162b33d0e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0 = df['class_0'].sum()\n",
    "count_class_1 = df['class_1'].sum()\n",
    "count_class_2 = df['class_2'].sum()\n",
    "print(f\"there is a {count_class_0} in class_0, a {count_class_1} in class_1, and a {count_class_2} in class_2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbb952-a19e-4df9-8650-0f4209e579fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('PLOSONE_DF-MacularStatus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aed041-3e80-45c5-a6aa-472e41904cea",
   "metadata": {},
   "source": [
    "# Preparation for MLA: Duration Estimation - 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3a4ea-6006-4ba5-8c95-5e961b2c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PLOSONE_DF.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c619430-f45a-4e44-b711-47f73b70889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = df['Duration of macular off in days'].value_counts()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a25b9-a442-4a5a-b372-a29aba850d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = df[\"Duration of macular off in days\"].count()\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a219b41-4f31-4f6d-b753-4dd66e6c0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Duration of macular off in days'] = df['Duration of macular off in days'].astype(str)\n",
    "df['Duration of macular off in days'] = df['Duration of macular off in days'].apply(lambda x: x.split('.')[0] if x != 'nan' else '')\n",
    "df['Duration of macular off in days'] = pd.to_numeric(df['Duration of macular off in days'], errors='coerce').astype('Int64')\n",
    "\n",
    "print(df['Duration of macular off in days'].unique())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da858aa1-78d5-49cc-b331-4830fff71f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value = (df[\"Makula status? On:1, Off:2\"] == 2).sum()\n",
    "print(count_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee3e08-3cd1-4587-8b68-531b2c950ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_1\"] = 0\n",
    "df.loc[(df[\"Macular status? On:1, Off:2\"] == 2) & (df[\"Duration of macular off in days\"] <= 3), \"class_1\"] = 1\n",
    "print(df[\"class_1\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4513c1d-ad5b-4c7a-9168-4e289c1f41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_2\"] = 0\n",
    "df.loc[(df[\"Macular status? On:1, Off:2\"] == 1) | (df[\"Duration of macular off in days\"] >= 4), \"class_2\"] = 1\n",
    "print(df[\"class_2\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd4d87-77a7-45b9-8a0d-a5a1c10e4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_0\"] = 0\n",
    "df['class_0'] = np.where(df['Non-RRD'] == 1.0, 1, df['class_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5de118-db86-4831-86b9-faa63c169b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_class_1 = df['class_0'].sum()\n",
    "sum_class_2 = df['class_1'].sum()\n",
    "sum_class_3 = df['class_2'].sum()\n",
    "\n",
    "print(\"Summe von class_0\", sum_class_1)\n",
    "print(\"Summe von class_1:\", sum_class_2)\n",
    "print(\"Summe von class_2:\", sum_class_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61650264-7344-45ea-8269-16aa26e973ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"class_2\"] == 1, \"class_0\"] += 1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade9834-02c4-417f-ad20-bd9418591537",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_class_1 = df['class_0'].sum()\n",
    "sum_class_2 = df['class_1'].sum()\n",
    "sum_class_3 = df['class_2'].sum()\n",
    "\n",
    "print(\"Summe von class_0\", sum_class_1)\n",
    "print(\"Summe von class_1:\", sum_class_2)\n",
    "print(\"Summe von class_2:\", sum_class_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66027cc-bda6-4f0a-9338-ae910f6d4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('PLOSONE_DF-Time.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
