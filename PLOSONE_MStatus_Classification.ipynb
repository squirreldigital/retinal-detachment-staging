{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cbcab-2cad-40e5-a5a6-11094c60c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Standard Library ───────────────────────────────────────────────────────────\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from itertools import cycle\n",
    "\n",
    "# ── Data Handling & Numerics ───────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "\n",
    "# ── PyTorch Ecosystem ──────────────────────────────────────────────────────────\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ── Computer Vision & Augmentations ────────────────────────────────────────────\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pydicom import dcmread\n",
    "\n",
    "# ── Scikit-Learn & Statistics ─────────────────────────────────────────────────\n",
    "import sklearn\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, auc, roc_curve, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from scipy import interp\n",
    "from scipy.stats import ttest_rel, ttest_ind\n",
    "\n",
    "# ── Visualization ─────────────────────────────────────────────────────────────\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ── Grad-CAM & Explainability ─────────────────────────────────────────────────\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "    AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    ")\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.feature_factorization.deep_feature_factorization import \\\n",
    "    DeepFeatureFactorization\n",
    "import pytorch_grad_cam.utils.model_targets\n",
    "import pytorch_grad_cam.utils.reshape_transforms\n",
    "import pytorch_grad_cam.metrics.cam_mult_image\n",
    "import pytorch_grad_cam.metrics.road\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46c48e-be0c-489c-ad31-36d8b6ff8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Dataset Directory\")\n",
    "visualization_dir = \"visualization_dir\"\n",
    "model_save_dir = \"Directory_Model\"\n",
    "df = pd.read_csv(\"PLOSONE_DF-MacularStatus.csv\") \n",
    "df[\"image_id\"] = np.arange(len(df))\n",
    "model_save_dir = \"model_checkpoints\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8343411",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [ 'class_0','class_1','class_2']\n",
    "class_labels = { name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 6\n",
    "num_classes = class_labels \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f63273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "class OctModel3D(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        # Load the 3D ResNet-18 model\n",
    "        self.model = r3d_18(pretrained=True)  # Pretrained 3D ResNet18\n",
    "\n",
    "        self.model.stem[0] = nn.Conv3d(\n",
    "            in_channels=1,\n",
    "            out_channels=self.model.stem[0].out_channels,\n",
    "            kernel_size=self.model.stem[0].kernel_size,\n",
    "            stride=self.model.stem[0].stride,\n",
    "            padding=self.model.stem[0].padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expects shape: (Batch, 1, Depth, Height, Width)\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize and move model to device\n",
    "model = OctModel3D(num_classes=3)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848209a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_volume(dicom_dir, target_shape=(64, 256, 256), cache_dir=None, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Load a series of DICOM files into a resized 3D tensor with GPU-based resizing.\n",
    "    \"\"\"\n",
    "    slices = []\n",
    "\n",
    "    # Check if path is a single file\n",
    "    if os.path.isfile(dicom_dir):\n",
    "        ds = pydicom.dcmread(dicom_dir)\n",
    "        slices.append(ds.pixel_array)\n",
    "    else:\n",
    "        for filename in sorted(os.listdir(dicom_dir)):\n",
    "            if filename.endswith('.dcm'):\n",
    "                dicom_path = os.path.join(dicom_dir, filename)\n",
    "                ds = pydicom.dcmread(dicom_path)\n",
    "                slices.append(ds.pixel_array)\n",
    "\n",
    "    if not slices:\n",
    "        raise ValueError(f\"No valid DICOM slices found in: {dicom_dir}\")\n",
    "\n",
    "    # Stack slices => shape [Depth, Height, Width]\n",
    "    volume = np.stack(slices, axis=0).astype(np.float32)\n",
    "\n",
    "    # Normalize the volume to [0, 1]\n",
    "    volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume) + 1e-8)\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    volume = torch.tensor(volume)\n",
    "\n",
    "    # Add batch=1, channel=1 => shape [1, 1, D, H, W]\n",
    "    if volume.ndim == 3:\n",
    "        volume = volume.unsqueeze(0).unsqueeze(0)\n",
    "    elif volume.ndim == 4:\n",
    "        volume = volume.unsqueeze(0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected volume shape {volume.shape}\")\n",
    "\n",
    "    # Resize to target_shape => [1,1,*target_shape]\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        volume = volume.cuda()\n",
    "        volume = F.interpolate(volume, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "        volume = volume.cpu()\n",
    "    else:\n",
    "        volume = F.interpolate(volume, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "\n",
    "    # Remove batch dimension => shape [1, D,H,W]\n",
    "    volume = volume.squeeze(0)\n",
    "\n",
    "    # Validate final shape\n",
    "    if volume.shape != (1, *target_shape):\n",
    "        raise ValueError(f\"Unexpected shape after resizing: {volume.shape}, expected: (1, {target_shape})\")\n",
    "\n",
    "    return volume\n",
    "\n",
    "class OctDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, class_names, target_shape=(64, 256, 256), cache_dir=None, use_gpu=True):\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.class_names = class_names\n",
    "        self.target_shape = target_shape\n",
    "        self.cache_dir = cache_dir\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dicom_dir = self.df.iloc[idx]['path3D']\n",
    "        try:\n",
    "            volume = load_dicom_volume(dicom_dir, target_shape=self.target_shape, cache_dir=self.cache_dir, use_gpu=self.use_gpu)\n",
    "        except ValueError as e:\n",
    "            raise RuntimeError(f\"Error loading DICOM at index {idx}: {e}\")\n",
    "\n",
    "        # volume => shape [1, D,H,W]\n",
    "        if volume.ndim != 4:\n",
    "            raise ValueError(f\"Volume shape is {volume.shape}, expected 4D (1, D, H, W)\")\n",
    "\n",
    "        # Load labels\n",
    "        labels = self.df.iloc[idx][self.class_names].values.astype(np.float32)\n",
    "        labels = torch.from_numpy(labels)\n",
    "\n",
    "        # Get sample ID\n",
    "        sample_id = self.df.iloc[idx]['image_id']\n",
    "        return volume, labels, sample_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64890b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "\n",
    "def get_current_time():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "##################################################\n",
    "# TRAIN FUNCTION\n",
    "##################################################\n",
    "def train_one_fold(v, t, model, criterion, optimizer,\n",
    "                   dataloader_train, dataloader_valid,\n",
    "\n",
    "    val_fold_results = []\n",
    "    best_fold_avg_precision = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_path = None\n",
    "    epoch_times = []\n",
    "\n",
    "    # Make sure N_EPOCHS is defined globally or pass it in\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        print(f\"[{get_current_time()}] Epoch {epoch + 1}/{N_EPOCHS}\")\n",
    "\n",
    "        #################\n",
    "        # TRAINING PHASE\n",
    "        #################\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        for batch_idx, batch in enumerate(dataloader_train):\n",
    "            images, labels = batch[0], batch[1]\n",
    "\n",
    "            # Move images to GPU/CPU\n",
    "            images = images.float().to(device)\n",
    "\n",
    "            if labels.ndim == 2 and labels.shape[1] == 3:\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # [batch_size, 3]\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "        ###################\n",
    "        # VALIDATION PHASE\n",
    "        ###################\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(dataloader_valid):\n",
    "                images, labels = batch[0], batch[1]\n",
    "\n",
    "                images = images.float().to(device)\n",
    "                # --------------[ OPTION A FIX ]--------------\n",
    "                if labels.ndim == 2 and labels.shape[1] == 3:\n",
    "                    labels = torch.argmax(labels, dim=1)\n",
    "                labels = labels.long().to(device)\n",
    "\n",
    "                outputs = model(images)  # [batch_size, 3]\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Store outputs & labels for metric\n",
    "                val_preds.extend(outputs.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Convert to NumPy\n",
    "        val_preds_np = np.array(val_preds)    # shape [N, 3]\n",
    "        val_labels_np = np.array(val_labels)  # shape [N], each in {0,1,2}\n",
    "\n",
    "        val_probs = F.softmax(torch.from_numpy(val_preds_np), dim=1).numpy()  # [N, 3]\n",
    "\n",
    "        # Convert labels -> one-hot for one-vs-rest macro AP\n",
    "        num_classes = 3\n",
    "        labels_one_hot = np.zeros((len(val_labels_np), num_classes), dtype=np.float32)\n",
    "        for i, lbl in enumerate(val_labels_np):\n",
    "            labels_one_hot[i, lbl] = 1.0\n",
    "\n",
    "        # Compute macro AP\n",
    "        try:\n",
    "            avg_precision_current = average_precision_score(labels_one_hot, val_probs, average=\"macro\")\n",
    "        except ValueError:\n",
    "\n",
    "            avg_precision_current = 0.0\n",
    "\n",
    "        print(f\"[{get_current_time()}] Val Avg Precision (macro): {avg_precision_current:.4f}\")\n",
    "\n",
    "        if avg_precision_current > best_fold_avg_precision:\n",
    "            best_fold_avg_precision = avg_precision_current\n",
    "            epochs_no_improve = 0\n",
    "            best_model_path = os.path.join(\n",
    "                model_save_dir,\n",
    "                f\"ModelV{v}_T{t}M-Status.pth\"\n",
    "            )\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"[{get_current_time()}] Best Model Saved at: {best_model_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"[{get_current_time()}] Early stopping at epoch: {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        print(f\"[{get_current_time()}] Time for Epoch {epoch + 1}: {epoch_time:.2f} seconds\")\n",
    "\n",
    "        # Record epoch stats\n",
    "        val_fold_results.append({\n",
    "            'TEST': t,\n",
    "            'VAL': v,\n",
    "            'epoch': epoch,\n",
    "            'train_loss': tr_loss / len(dataloader_train),\n",
    "            'valid_loss': val_loss / len(dataloader_valid),\n",
    "            'valid_avg_precision': avg_precision_current,\n",
    "            'time': epoch_time\n",
    "        })\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(epoch_times)+1), epoch_times, marker='o')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.title(f\"Epoch Timing - Fold {v}-{t}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return val_fold_results, best_fold_avg_precision, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#Test\n",
    "##################################################\n",
    "\n",
    "\n",
    "aggregated_results = []\n",
    "N_FOLDS = 5\n",
    "\n",
    "for test_fold in range(N_FOLDS):\n",
    "    for val_fold in range(N_FOLDS):\n",
    "        if test_fold != val_fold:\n",
    "            # 1) Initialize model for 3 classes\n",
    "            model = OctModel3D(num_classes=3).to(device)\n",
    "            model.apply(reset_weights)\n",
    "\n",
    "            # 2) Prepare splits\n",
    "            val_df = df[df[\"fold\"] == val_fold].reset_index(drop=True)\n",
    "            train_df = df[(df[\"fold\"] != test_fold) & (df[\"fold\"] != val_fold)].reset_index(drop=True)\n",
    "            test_df = df[df[\"fold\"] == test_fold].reset_index(drop=True)\n",
    "\n",
    "            print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "            # 3) Create Datasets / DataLoaders\n",
    "            dataset_train = OctDataset(df=train_df, class_names=class_names)\n",
    "            dataset_valid = OctDataset(df=val_df, class_names=class_names)\n",
    "            dataset_test  = OctDataset(df=test_df, class_names=class_names)\n",
    "\n",
    "            dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "            dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "            dataloader_test  = DataLoader(dataset_test,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "            # 4) Training setup\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "            # 5) Train & validate (3-class single-label)\n",
    "            val_fold_results, best_fold_ap, best_model_path = train_one_fold(\n",
    "                v=test_fold,\n",
    "                t=val_fold,\n",
    "                model=model,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                dataloader_train=dataloader_train,\n",
    "                dataloader_valid=dataloader_valid,\n",
    "                model_save_dir=model_save_dir,\n",
    "                patience=10\n",
    "            )\n",
    "\n",
    "            # 6) Load best model for testing\n",
    "            model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "            model.eval()\n",
    "\n",
    "            # 7) TEST PHASE\n",
    "            fold_test_targets = []\n",
    "            fold_test_probabilities = []\n",
    "            fold_test_ids = []\n",
    "            predictions = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in dataloader_test:\n",
    "                    images, labels, ids = batch\n",
    "                    images = images.float().to(device)\n",
    "\n",
    "                    # Convert one-hot => int if needed\n",
    "                    if labels.ndim == 2 and labels.shape[1] == 3:\n",
    "                        labels = labels.argmax(dim=1)\n",
    "                    labels = labels.long()  # CPU is OK for storing results\n",
    "\n",
    "                    outputs = model(images)            # [batch_size, 3]\n",
    "                    probs = torch.softmax(outputs, dim=1).cpu().numpy()  # [batch_size, 3]\n",
    "\n",
    "                    batch_preds = np.argmax(probs, axis=1)\n",
    "                    predictions.extend(batch_preds)\n",
    "                    fold_test_probabilities.extend(probs)\n",
    "                    fold_test_targets.extend(labels.numpy())\n",
    "                    # sample_id might be a tensor or direct value\n",
    "                    if hasattr(ids, \"numpy\"):\n",
    "                        fold_test_ids.extend(ids.numpy())\n",
    "                    else:\n",
    "                        fold_test_ids.extend(ids)\n",
    "\n",
    "            # Convert to NumPy\n",
    "            test_targets_np = np.array(fold_test_targets)       # shape [N], each ∈ {0..2}\n",
    "            test_probs_np   = np.array(fold_test_probabilities) # shape [N, 3]\n",
    "\n",
    "            # 7a) Multi-class ROC AUC (macro, one-vs-rest)\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(test_targets_np, test_probs_np,\n",
    "                                        multi_class='ovr', average='macro')\n",
    "            except ValueError:\n",
    "                roc_auc = 0.0\n",
    "\n",
    "            print(f\"[TestFold={test_fold}, ValFold={val_fold}] ROC AUC (macro, ovr): {roc_auc:.4f}\")\n",
    "\n",
    "            # 8) Identify correct predictions\n",
    "            correct_indices = [i for i in range(len(predictions))\n",
    "                               if predictions[i] == test_targets_np[i]]\n",
    "            num_correct = len(correct_indices)\n",
    "            print(f\"Correct Predictions: {num_correct}/{len(test_targets_np)}\")\n",
    "\n",
    "            # 9) Store final results\n",
    "            sub = pd.DataFrame(test_probs_np, columns=[\"pred0\",\"pred1\",\"pred2\"])\n",
    "            sub[\"image_id\"] = fold_test_ids\n",
    "            sub[\"test_fold\"] = test_fold\n",
    "            sub[\"val_fold\"] = val_fold\n",
    "            sub[\"predicted_class\"] = predictions\n",
    "            sub[\"actual_class\"] = test_targets_np\n",
    "            sub[\"roc_auc\"] = roc_auc\n",
    "\n",
    "            aggregated_results.append(sub)\n",
    "\n",
    "# Concatenate final results\n",
    "final_results = pd.concat(aggregated_results, ignore_index=True)\n",
    "print(\"Final Results (head):\")\n",
    "print(final_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d1040-ef78-4eda-9e9b-3674464a1216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
